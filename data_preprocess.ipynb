{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5375701-3b90-42f5-851b-b9ea79bb4805",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88bf438f-cf25-4b26-a499-bb4234d0081c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "def normalize_data(data):\n",
    "    \"\"\"\n",
    "    Normalize a signal using min-max normalization.\n",
    "    \n",
    "    Parameters:\n",
    "    - signal: Input signal (numpy array or list)\n",
    "    \n",
    "    Returns:\n",
    "    - normalized_signal: Normalized signal\n",
    "    \"\"\"\n",
    "    \n",
    "    row, __ = data.shape\n",
    "    processed_data = np.zeros(data.shape)\n",
    "    \n",
    "    for lead in range(row):\n",
    "        # Calculate the minimum and maximum values of the signal\n",
    "        min_val = np.min(data[lead])\n",
    "        max_val = np.max(data[lead])\n",
    "\n",
    "        # Perform min-max normalization\n",
    "        normalized_signal = (data[lead] - min_val) / (max_val - min_val)\n",
    "        \n",
    "        processed_data[lead] = normalized_signal\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# baseline \n",
    "def baseline(data):\n",
    "    row,__ = data.shape\n",
    "    sampling_frequency = 500\n",
    "\n",
    "    win_size = int(np.round(0.2 * sampling_frequency)) + 1\n",
    "    baseline = scipy.ndimage.median_filter(data, [1, win_size], mode=\"constant\")\n",
    "    win_size = int(np.round(0.6 * sampling_frequency)) + 1\n",
    "    baseline = scipy.ndimage.median_filter(baseline, [1, win_size], mode=\"constant\")\n",
    "    filt_data = data - baseline\n",
    "\n",
    "    return filt_data\n",
    "\n",
    "# notch filter\n",
    "def notch(data):\n",
    "    sampling_frequency = 500\n",
    "    row, __ = data.shape\n",
    "    processed_data = np.zeros(data.shape)\n",
    "    b = np.ones(int(0.02 * sampling_frequency)) / 50.\n",
    "    a = [1]\n",
    "    for lead in range(0, row):\n",
    "        X = scipy.signal.filtfilt(b, a, data[lead,:])\n",
    "        processed_data[lead,:] = X\n",
    "        \n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb34797-748b-4ad7-a4f3-d0bcdd699d6a",
   "metadata": {},
   "source": [
    "#### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ac656-1d35-48ee-b3e5-8a4ea3ef5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg[\"dataloader\"][\"normalize_y\"]  # True\n",
    "# cfg[\"dataloader\"][\"notch_filter\"]   # False\n",
    "# cfg[\"dataloader\"][\"baseline_filter\"]  # True\n",
    "# cfg[\"dataloader\"][\"mean_zero\"]  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b956bad6-9857-401c-95a3-c211e12e3096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preprocessed!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ecg\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "mode = \"train\"\n",
    "task = \"scd_classification\"\n",
    "cfg_updates={}\n",
    "\n",
    "# configaration\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    config.task_cfg[task],\n",
    ")\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    cfg_updates,\n",
    ")\n",
    "\n",
    "if mode == \"train\":\n",
    "\n",
    "    # using TensorDataset to creat dataset directly\n",
    "    waveform_file_path = cfg[\"dataloader\"][\"waveforms_file\"]\n",
    "    ecg_waveforms = np.load(waveform_file_path).astype(np.float32)\n",
    "\n",
    "    labels_file_path = cfg[\"dataloader\"][\"label_file\"]\n",
    "    ecg_labels = np.array(pd.read_csv(labels_file_path)[cfg[\"dataloader\"][\"label_keys\"]])\n",
    "\n",
    "    # do some preprocess to the waveforms data\n",
    "    if (cfg[\"dataloader\"][\"normalize_y\"] or cfg[\"dataloader\"][\"notch_filter\"] \n",
    "        or cfg[\"dataloader\"][\"baseline_filter\"] or cfg[\"dataloader\"][\"mean_zero\"]):\n",
    "\n",
    "        for i in range(len(ecg_waveforms)):\n",
    "\n",
    "            # baseline filter\n",
    "            if cfg[\"dataloader\"][\"baseline_filter\"]:\n",
    "                ecg_waveforms[i] = baseline(ecg_waveforms[i])\n",
    "\n",
    "            # notch filter\n",
    "            if cfg[\"dataloader\"][\"notch_filter\"]:\n",
    "                ecg_waveforms[i] = notch(ecg_waveforms[i])\n",
    "\n",
    "            # normalization\n",
    "            if cfg[\"dataloader\"][\"normalize_y\"]:\n",
    "                ecg_waveforms[i] = normalize_data(ecg_waveforms[i])\n",
    "\n",
    "            # zero mean\n",
    "            if cfg[\"dataloader\"][\"mean_zero\"]:\n",
    "                for lead in range(len(ecg_waveforms[i])):\n",
    "                    ecg_waveforms[i][lead] = ecg_waveforms[i][lead] - np.mean(ecg_waveforms[i][lead])\n",
    "\n",
    "        print('data preprocessed!')\n",
    "\n",
    "    # Step 1: Split into training and test data \n",
    "    temp_data, test_data, temp_labels, test_labels = train_test_split(ecg_waveforms, ecg_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # Step 2: Split the temporary data into training and validation sets\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(temp_data, temp_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    waveforms = {\"train\": train_data,\n",
    "                \"test\": test_data,\n",
    "                \"valid\": val_data,\n",
    "                \"all\": ecg_waveforms}\n",
    "\n",
    "    labels = {\"train\": train_labels,\n",
    "            \"test\": test_labels,\n",
    "            \"valid\": val_labels,\n",
    "             \"all\": ecg_labels}\n",
    "\n",
    "    # creat datasets\n",
    "    datasets = {k: TensorDataset(torch.tensor(waveforms[k], dtype=torch.float32), \n",
    "                                 torch.tensor(labels[k], dtype=torch.float32)) \n",
    "                for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "    \n",
    "\n",
    "# Save the datasets to a file\n",
    "torch.save(datasets, 'datasets_baseline_norm_zero.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5db94-1733-4770-985d-eb945f80ea15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove nan\n",
    "\n",
    "# load dataset directly\n",
    "datasets = torch.load('datasets_baseline_norm_zero.pth')\n",
    "\n",
    "filtered_datasets = {}\n",
    "\n",
    "for k in [\"train\", \"valid\", \"test\", \"all\"]:\n",
    "    filtered_data, filtered_labels = zip(*[(data, label) for data, label in datasets[k] if not torch.isnan(data).any().item()])\n",
    "    filtered_datasets[k] = TensorDataset(torch.stack(filtered_data), torch.stack(filtered_labels))\n",
    "\n",
    "# Save the datasets to a file\n",
    "torch.save(filtered_datasets, 'datasets_baseline_norm_zero_remove_nan.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cde95-7291-4e80-91d4-94e0e528a394",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5f5be2-2d58-4b1b-a1bc-c5850897722b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preprocessed!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ecg\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "mode = \"train\"\n",
    "task = \"scd_classification\"\n",
    "cfg_updates={}\n",
    "\n",
    "# configaration\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    config.task_cfg[task],\n",
    ")\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    cfg_updates,\n",
    ")\n",
    "\n",
    "cfg[\"dataloader\"][\"normalize_y\"] = False\n",
    "\n",
    "if mode == \"train\":\n",
    "\n",
    "    # using the new dataset defined by myself\n",
    "    # datasets = {k: ECGDataset(cfg[\"dataloader\"], k) for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "\n",
    "    # the original defined dataset\n",
    "    # datasets = {k: ECGDataset(cfg[\"dataloader\"], k, output=output, all_waveforms=True) for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "\n",
    "    # using TensorDataset to creat dataset directly\n",
    "    waveform_file_path = cfg[\"dataloader\"][\"waveforms_file\"]\n",
    "    ecg_waveforms = np.load(waveform_file_path).astype(np.float32)\n",
    "\n",
    "    labels_file_path = cfg[\"dataloader\"][\"label_file\"]\n",
    "    ecg_labels = np.array(pd.read_csv(labels_file_path)[cfg[\"dataloader\"][\"label_keys\"]])\n",
    "\n",
    "    # do some preprocess to the waveforms data\n",
    "    if (cfg[\"dataloader\"][\"normalize_y\"] or cfg[\"dataloader\"][\"notch_filter\"] \n",
    "        or cfg[\"dataloader\"][\"baseline_filter\"] or cfg[\"dataloader\"][\"mean_zero\"]):\n",
    "\n",
    "        for i in range(len(ecg_waveforms)):\n",
    "\n",
    "            # baseline filter\n",
    "            if cfg[\"dataloader\"][\"baseline_filter\"]:\n",
    "                ecg_waveforms[i] = baseline(ecg_waveforms[i])\n",
    "\n",
    "            # notch filter\n",
    "            if cfg[\"dataloader\"][\"notch_filter\"]:\n",
    "                ecg_waveforms[i] = notch(ecg_waveforms[i])\n",
    "\n",
    "            # normalization\n",
    "            if cfg[\"dataloader\"][\"normalize_y\"]:\n",
    "                ecg_waveforms[i] = normalize_data(ecg_waveforms[i])\n",
    "\n",
    "            # zero mean\n",
    "            if cfg[\"dataloader\"][\"mean_zero\"]:\n",
    "                for lead in range(len(ecg_waveforms[i])):\n",
    "                    ecg_waveforms[i][lead] = ecg_waveforms[i][lead] - np.mean(ecg_waveforms[i][lead])\n",
    "\n",
    "        print('data preprocessed!')\n",
    "\n",
    "    # Step 1: Split into training and test data \n",
    "    temp_data, test_data, temp_labels, test_labels = train_test_split(ecg_waveforms, ecg_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # Step 2: Split the temporary data into training and validation sets\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(temp_data, temp_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    waveforms = {\"train\": train_data,\n",
    "                \"test\": test_data,\n",
    "                \"valid\": val_data,\n",
    "                \"all\": ecg_waveforms}\n",
    "\n",
    "    labels = {\"train\": train_labels,\n",
    "            \"test\": test_labels,\n",
    "            \"valid\": val_labels,\n",
    "             \"all\": ecg_labels}\n",
    "\n",
    "    # creat datasets\n",
    "    datasets = {k: TensorDataset(torch.tensor(waveforms[k], dtype=torch.float32), \n",
    "                                 torch.tensor(labels[k], dtype=torch.float32)) \n",
    "                for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "    \n",
    "\n",
    "# Save the datasets to a file\n",
    "torch.save(datasets, 'datasets_baseline_zero.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d7815-a880-44cc-bb6a-701f35aaedc3",
   "metadata": {},
   "source": [
    "#### Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b4374b-4cd2-4498-9ec1-cc5cbc4d5415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preprocessed!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ecg\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "mode = \"train\"\n",
    "task = \"scd_classification\"\n",
    "cfg_updates={}\n",
    "\n",
    "# configaration\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    config.task_cfg[task],\n",
    ")\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    cfg_updates,\n",
    ")\n",
    "\n",
    "cfg[\"dataloader\"][\"normalize_y\"] = False\n",
    "cfg[\"dataloader\"][\"baseline_filter\"] = False\n",
    "\n",
    "if mode == \"train\":\n",
    "\n",
    "    # using the new dataset defined by myself\n",
    "    # datasets = {k: ECGDataset(cfg[\"dataloader\"], k) for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "\n",
    "    # the original defined dataset\n",
    "    # datasets = {k: ECGDataset(cfg[\"dataloader\"], k, output=output, all_waveforms=True) for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "\n",
    "    # using TensorDataset to creat dataset directly\n",
    "    waveform_file_path = cfg[\"dataloader\"][\"waveforms_file\"]\n",
    "    ecg_waveforms = np.load(waveform_file_path).astype(np.float32)\n",
    "\n",
    "    labels_file_path = cfg[\"dataloader\"][\"label_file\"]\n",
    "    ecg_labels = np.array(pd.read_csv(labels_file_path)[cfg[\"dataloader\"][\"label_keys\"]])\n",
    "\n",
    "    # do some preprocess to the waveforms data\n",
    "    if (cfg[\"dataloader\"][\"normalize_y\"] or cfg[\"dataloader\"][\"notch_filter\"] \n",
    "        or cfg[\"dataloader\"][\"baseline_filter\"] or cfg[\"dataloader\"][\"mean_zero\"]):\n",
    "\n",
    "        for i in range(len(ecg_waveforms)):\n",
    "\n",
    "            # baseline filter\n",
    "            if cfg[\"dataloader\"][\"baseline_filter\"]:\n",
    "                ecg_waveforms[i] = baseline(ecg_waveforms[i])\n",
    "\n",
    "            # notch filter\n",
    "            if cfg[\"dataloader\"][\"notch_filter\"]:\n",
    "                ecg_waveforms[i] = notch(ecg_waveforms[i])\n",
    "\n",
    "            # normalization\n",
    "            if cfg[\"dataloader\"][\"normalize_y\"]:\n",
    "                ecg_waveforms[i] = normalize_data(ecg_waveforms[i])\n",
    "\n",
    "            # zero mean\n",
    "            if cfg[\"dataloader\"][\"mean_zero\"]:\n",
    "                for lead in range(len(ecg_waveforms[i])):\n",
    "                    ecg_waveforms[i][lead] = ecg_waveforms[i][lead] - np.mean(ecg_waveforms[i][lead])\n",
    "\n",
    "        print('data preprocessed!')\n",
    "\n",
    "    # Step 1: Split into training and test data \n",
    "    temp_data, test_data, temp_labels, test_labels = train_test_split(ecg_waveforms, ecg_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # Step 2: Split the temporary data into training and validation sets\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(temp_data, temp_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    waveforms = {\"train\": train_data,\n",
    "                \"test\": test_data,\n",
    "                \"valid\": val_data,\n",
    "                \"all\": ecg_waveforms}\n",
    "\n",
    "    labels = {\"train\": train_labels,\n",
    "            \"test\": test_labels,\n",
    "            \"valid\": val_labels,\n",
    "             \"all\": ecg_labels}\n",
    "\n",
    "    # creat datasets\n",
    "    datasets = {k: TensorDataset(torch.tensor(waveforms[k], dtype=torch.float32), \n",
    "                                 torch.tensor(labels[k], dtype=torch.float32)) \n",
    "                for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "    \n",
    "\n",
    "# Save the datasets to a file\n",
    "torch.save(datasets, 'datasets_zero.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34f89f-975e-498d-bb81-167695aa3b50",
   "metadata": {},
   "source": [
    "#### Dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2712cc-81d9-40f8-8351-f996587f77cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import ecg\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "mode = \"train\"\n",
    "task = \"scd_classification\"\n",
    "cfg_updates={}\n",
    "\n",
    "# configaration\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    config.task_cfg[task],\n",
    ")\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    cfg_updates,\n",
    ")\n",
    "\n",
    "cfg[\"dataloader\"][\"normalize_y\"] = False\n",
    "cfg[\"dataloader\"][\"baseline_filter\"] = False\n",
    "cfg[\"dataloader\"][\"mean_zero\"] = False\n",
    "\n",
    "if mode == \"train\":\n",
    "\n",
    "    # using the new dataset defined by myself\n",
    "    # datasets = {k: ECGDataset(cfg[\"dataloader\"], k) for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "\n",
    "    # the original defined dataset\n",
    "    # datasets = {k: ECGDataset(cfg[\"dataloader\"], k, output=output, all_waveforms=True) for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "\n",
    "    # using TensorDataset to creat dataset directly\n",
    "    waveform_file_path = cfg[\"dataloader\"][\"waveforms_file\"]\n",
    "    ecg_waveforms = np.load(waveform_file_path).astype(np.float32)\n",
    "\n",
    "    labels_file_path = cfg[\"dataloader\"][\"label_file\"]\n",
    "    ecg_labels = np.array(pd.read_csv(labels_file_path)[cfg[\"dataloader\"][\"label_keys\"]])\n",
    "\n",
    "    # do some preprocess to the waveforms data\n",
    "    if (cfg[\"dataloader\"][\"normalize_y\"] or cfg[\"dataloader\"][\"notch_filter\"] \n",
    "        or cfg[\"dataloader\"][\"baseline_filter\"] or cfg[\"dataloader\"][\"mean_zero\"]):\n",
    "\n",
    "        for i in range(len(ecg_waveforms)):\n",
    "\n",
    "            # baseline filter\n",
    "            if cfg[\"dataloader\"][\"baseline_filter\"]:\n",
    "                ecg_waveforms[i] = baseline(ecg_waveforms[i])\n",
    "\n",
    "            # notch filter\n",
    "            if cfg[\"dataloader\"][\"notch_filter\"]:\n",
    "                ecg_waveforms[i] = notch(ecg_waveforms[i])\n",
    "\n",
    "            # normalization\n",
    "            if cfg[\"dataloader\"][\"normalize_y\"]:\n",
    "                ecg_waveforms[i] = normalize_data(ecg_waveforms[i])\n",
    "\n",
    "            # zero mean\n",
    "            if cfg[\"dataloader\"][\"mean_zero\"]:\n",
    "                for lead in range(len(ecg_waveforms[i])):\n",
    "                    ecg_waveforms[i][lead] = ecg_waveforms[i][lead] - np.mean(ecg_waveforms[i][lead])\n",
    "\n",
    "        print('data preprocessed!')\n",
    "\n",
    "    # Step 1: Split into training and test data \n",
    "    temp_data, test_data, temp_labels, test_labels = train_test_split(ecg_waveforms, ecg_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # Step 2: Split the temporary data into training and validation sets\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(temp_data, temp_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    waveforms = {\"train\": train_data,\n",
    "                \"test\": test_data,\n",
    "                \"valid\": val_data,\n",
    "                \"all\": ecg_waveforms}\n",
    "\n",
    "    labels = {\"train\": train_labels,\n",
    "            \"test\": test_labels,\n",
    "            \"valid\": val_labels,\n",
    "             \"all\": ecg_labels}\n",
    "\n",
    "    # creat datasets\n",
    "    datasets = {k: TensorDataset(torch.tensor(waveforms[k], dtype=torch.float32), \n",
    "                                 torch.tensor(labels[k], dtype=torch.float32)) \n",
    "                for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "    \n",
    "\n",
    "# Save the datasets to a file\n",
    "torch.save(datasets, 'datasets.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b731841-377c-4a56-ab67-5e3caa03a5d3",
   "metadata": {},
   "source": [
    "#### Dataset 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5912eae0-75c9-4108-a7a2-6891d5733223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg[\"dataloader\"][\"normalize_y\"]  # True\n",
    "# cfg[\"dataloader\"][\"notch_filter\"]   # True\n",
    "# cfg[\"dataloader\"][\"baseline_filter\"]  # True\n",
    "# cfg[\"dataloader\"][\"mean_zero\"]  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077f0915-b3cd-400b-8f5a-bc31f254e8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12092/915985723.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_signal = (data[lead] - min_val) / (max_val - min_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preprocessed!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ecg\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "mode = \"train\"\n",
    "task = \"scd_classification\"\n",
    "cfg_updates={}\n",
    "\n",
    "# configaration\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    config.task_cfg[task],\n",
    ")\n",
    "cfg = config.update_config_dict(\n",
    "    config.cfg,\n",
    "    cfg_updates,\n",
    ")\n",
    "\n",
    "cfg[\"dataloader\"][\"notch_filter\"] = True\n",
    "\n",
    "if mode == \"train\":\n",
    "\n",
    "    # using TensorDataset to creat dataset directly\n",
    "    waveform_file_path = cfg[\"dataloader\"][\"waveforms_file\"]\n",
    "    ecg_waveforms = np.load(waveform_file_path).astype(np.float32)\n",
    "\n",
    "    labels_file_path = cfg[\"dataloader\"][\"label_file\"]\n",
    "    ecg_labels = np.array(pd.read_csv(labels_file_path)[cfg[\"dataloader\"][\"label_keys\"]])\n",
    "\n",
    "    # do some preprocess to the waveforms data\n",
    "    if (cfg[\"dataloader\"][\"normalize_y\"] or cfg[\"dataloader\"][\"notch_filter\"] \n",
    "        or cfg[\"dataloader\"][\"baseline_filter\"] or cfg[\"dataloader\"][\"mean_zero\"]):\n",
    "\n",
    "        for i in range(len(ecg_waveforms)):\n",
    "\n",
    "            # baseline filter\n",
    "            if cfg[\"dataloader\"][\"baseline_filter\"]:\n",
    "                ecg_waveforms[i] = baseline(ecg_waveforms[i])\n",
    "\n",
    "            # notch filter\n",
    "            if cfg[\"dataloader\"][\"notch_filter\"]:\n",
    "                ecg_waveforms[i] = notch(ecg_waveforms[i])\n",
    "\n",
    "            # normalization\n",
    "            if cfg[\"dataloader\"][\"normalize_y\"]:\n",
    "                ecg_waveforms[i] = normalize_data(ecg_waveforms[i])\n",
    "\n",
    "            # zero mean\n",
    "            if cfg[\"dataloader\"][\"mean_zero\"]:\n",
    "                for lead in range(len(ecg_waveforms[i])):\n",
    "                    ecg_waveforms[i][lead] = ecg_waveforms[i][lead] - np.mean(ecg_waveforms[i][lead])\n",
    "\n",
    "        print('data preprocessed!')\n",
    "\n",
    "    # Step 1: Split into training and test data \n",
    "    temp_data, test_data, temp_labels, test_labels = train_test_split(ecg_waveforms, ecg_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # Step 2: Split the temporary data into training and validation sets\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(temp_data, temp_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    waveforms = {\"train\": train_data,\n",
    "                \"test\": test_data,\n",
    "                \"valid\": val_data,\n",
    "                \"all\": ecg_waveforms}\n",
    "\n",
    "    labels = {\"train\": train_labels,\n",
    "            \"test\": test_labels,\n",
    "            \"valid\": val_labels,\n",
    "             \"all\": ecg_labels}\n",
    "\n",
    "    # creat datasets\n",
    "    datasets = {k: TensorDataset(torch.tensor(waveforms[k], dtype=torch.float32), \n",
    "                                 torch.tensor(labels[k], dtype=torch.float32)) \n",
    "                for k in [\"train\", \"valid\", \"test\", \"all\"]}\n",
    "    \n",
    "\n",
    "# Save the datasets to a file\n",
    "torch.save(datasets, 'datasets_baseline_notch_norm_zero.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4359845-1967-4709-b876-4e6d3cb95c94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove nan\n",
    "\n",
    "# load dataset directly\n",
    "datasets = torch.load('datasets_baseline_notch_norm_zero.pth')\n",
    "\n",
    "filtered_datasets = {}\n",
    "\n",
    "for k in [\"train\", \"valid\", \"test\", \"all\"]:\n",
    "    filtered_data, filtered_labels = zip(*[(data, label) for data, label in datasets[k] if not torch.isnan(data).any().item()])\n",
    "    filtered_datasets[k] = TensorDataset(torch.stack(filtered_data), torch.stack(filtered_labels))\n",
    "\n",
    "# Save the datasets to a file\n",
    "torch.save(filtered_datasets, 'datasets_baseline_notch_norm_zero_remove_nan.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
